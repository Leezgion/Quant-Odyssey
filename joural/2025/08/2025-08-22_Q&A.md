# Q&A: 2025-08-22

## 除了优化读取方式，我们是否可以从文件格式本身入手来优化呢？ 也就是说，CSV 格式对于存储大规模金融数据来说，是最好的选择吗？它有什么天生的缺点？

### **核心概念：行式存储 (Row-Based) vs. 列式存储 (Columnar)**

要理解 Parquet/Feather 的威力，首先要明白它们与 CSV 在底层设计上的根本区别。

* **CSV (行式存储):**
  * 数据是按“行”来存储的。文件就像这样：
      `2023-01-01,100,103,99,102,1000\n`
      `2023-01-02,102,106,101,105,1500\n`
  * **优点：** 非常直观，适合逐条写入（比如日志录），兼容性极佳。
  * **缺点：** 当你做分析时，通常只关心某几“列（比如我只想计算所有 `close` 价格的平均值），行式存储迫使你必须从头到尾读取整个文件，把每一的所有数据都过一遍，然后丢掉不用的列。这在数据大时是巨大的浪费。

* **Parquet/Feather (列式存储):**
  * 数据是按“列”来存储的。在文件内部，它更像是这样：
    `(所有open_time), (所有open), (high), (所有low), (所有close), (volume)`
  * **优点:**
    1. **读取高效:** 当你只想计算 `close平均值时，程序可以直接跳到存储`close`的那个数据块，只读取那一列，忽略其列。I/O开销大大降低。
    2. **压缩率高:** 同一列的数据类型相是数字，或全是日期），重复度高，因此易被压缩。比如 `[100, 102, 105, 103]比`['2023-01-01', 100, 'some_text']压缩得多。

#### **1. Parquet**

* **它是什么：** 一个开源的、为分析而生的**列式存储格式**。它是大数据生态（Hadoop, Spark）的事实标准，但现在在单机数据分析中也极其流行。
* **核心特性：**
  * **列式存储：** 只读你需要的列。
  * **高压缩比：** 支持多种压缩算法（如Snappy,Gzip, ZSTD），文件体积通常远小于CSV。
  * **模式演化 (Schema Evolution)：** 可以平地增加、删除或修改列，而不会破坏旧数据。
  * **自带元数据：** 文件本身包含了每列的类型、计信息（最大/最小值等），这让查询优化成为可能。
* **生活中的比喻：**
    Parquet 就像一个**智能化的多层档案柜**。CSV 是把每个人的所有资料（姓名、年龄、住址）都放在一个文件夹里，然后按顺序堆叠。而 Parquet 则是把所有人的“姓名页”放在一个抽屉，所有人的“年龄页”放在另一个抽屉。当你需要所有人的年龄时，你只需打开“年龄”抽屉，而不用翻阅每个人的整个文件夹。

#### **2. Feather**

* **它是什么：** 一个基于 **Apache Arrow** 内存格式的、为速度而生的**二进制文件格式**。
* **核心特性：**
  * **极致的读写速度：** 它的设计目标就是让数据内存（DataFrame）和硬盘之间进行最快速度的交换几乎没有转换开销。
  * **无压缩（默认）：** 速度是第一位的，所以它牲了压缩能力，文件体积通常比 Parquet 大。
  * **跨语言：** 因为基于Arrow，Python, R, Java等语言可以零成本地共享数据。
* **生活中的比喻：**
    Feather 就像是电脑的“剪贴板”或者“内存快照”。当你复制粘贴时，系统会用一种内部格式快速暂存数据。Feather就是把内存中的DataFrame以最接近其原始形态的方式直接“拍”到硬盘上，下次加载时再原样“读”回内存，所以速度飞快。

#### **3. HDF5 (Hierarchical Data Format 5)**

* **它是什么：** 一个为存储和组织海量科学与工程数据设计的**文件格式和库**。
* **核心特性：**
  * **层次结构：** 可以在一个 HDF5 文件内部创建似文件系统一样的组（目录）和数据集（文件）。
  * **支持分块和索引：** 可以只读取一个巨大数（比如一张高分辨率卫星图）的其中一小块，而无需载整个文件。
  * **支持元数据：** 可以给数据附加各种描述性息。
* **生活中的比喻：**
    HDF5 就像一个**功能强大的 ZIP 压缩包**。你可以在这个包里创建文件夹，存放不同类型的文件，而且可以只解压其中某一个文件夹里的某一个小文件，而不用解压整个包。

#### **4. SQLite / DuckDB 与 Arrow 的关系**

* **SQLite:** 是一个轻量级的、文件级的**关系型数据库 (SQL Database)**。它是一个完整的数据库，支持SQL查询、事务、索引等。它是**行式存储**的。
* **Apache Arrow:** 它**不是一个存储格式**，而是一个**内存中列式数据的规范**。它的目标是让不同系统（Pandas, Spark, DuckDB）在处理数据时，无需进行昂贵的数据序列化和反序列化，可以直接在内存中共享数据。Feather 格式就是 Arrow 内存规范的硬盘实现。
* **DuckDB:** 这是近年来的新星，可以看作是“为分析而生的SQLite”。它是一个**内嵌式（in-process）的列式分析数据库**。它使用 SQL 作为查询语言，但底层是列式执行引擎，速度极快，并且可以直接查询 Parquet 文件，与 Pandas/Arrow 结合得天衣无缝。

---

### **我们的项目可能会使用哪个？**

你的总结非常精准，在实际项目中，我们通常会组合使用它们。对于我们的量化交易项目，我建议的策略是：

1. **原始历史数据存储 (Raw Data Lake) → 使用 Parquet**
    * **场景：** 我们会从交易所下载几年甚至十几年的分钟级、小时级或日线级的K线数据。这些数据量很大，下载一次后会长期使用。
    * **原因：** Parquet 的高压缩率可以极大地节省你的硬盘空间。其列式特性意味着，当我们做特征工程时（比如只需要`close`和`volume`列），读取速度会远超CSV。它是我们数据仓库的基石。

2. **中间过程/特征存储 (Feature Store) → 使用 Parquet 或 Feather**
    * **场景：** 我们基于原始数据计算了大量的技术指标（如MA, RSI, 布林带等），形成了一个新的、更宽的DataFrame。我们需要把它存下来，供模型训练使用。
    * **选择：**
        * 如果这个计算过程很长，而你只是想快速把结果存下来，下一步马上就要用，可以用 **Feather**，图它的读写快。
        * 但更稳妥、更通用的做法是存为 **Parquet**。因为它同样很快，而且更节省空间，也更利于长期归档和分享。**我个人更推荐Parquet作为默认选项。**

3. **复杂的数据探索与查询 → 使用 DuckDB**
    * **场景：** 在你进行研究时，可能会有一些临时的、复杂的查询需求，比如：“筛选出过去5年里，所有周三的、交易量是当周平均交易量两倍以上、且收盘价上涨超过3%的日线数据”。
    * **原因：** 这种复杂的多条件聚合查询，用Pandas写起来会比较繁琐。而用 DuckDB，你可以直接在Python脚本里写一段SQL，对你的Parquet文件进行查询，代码清晰且执行效率极高。

**结论：**

* **主力存储格式：Parquet。** 我们所有下载的、清洗好的、生成特征的数据，都以它为标准格式。
* **临时高速缓存：Feather。** 在单个复杂脚本的不同步骤间传递数据时可选。
* **瑞士军刀（高级查询工具）：DuckDB。** 当Pandas查询变得复杂时，用它来写SQL。
* **彻底告别：CSV。** 只在从外部源（如交易所API下载）获取数据时作为初始格式，一旦入手，**立刻转换为Parquet**。

## [5million行的DataFrame文件读写测试以及列读取测试](./2025-08-22-001.ipynb)

A:写入这个5million行的DataFrame时，Feather最快，Parquet大约耗时是Feather的两倍，CSV耗时最久比Parquet耗时多达30倍左右。读取文件时，Feather与Parquet耗时相近，Parquet略快，CSV耗时还是30倍左右。列读取测试中CSV耗时增加到了Parquet和Feather耗时的将近80倍，Parquet和Feather耗时相近，Feather略快。

### **结果解读与分析**

#### **1. 关于写入性能：`Feather > Parquet >> CSV`**

* **Feather为什么最快？**
  * 你的结论完全正确。Feather的写入过程几乎是内存数据到硬盘的直接“倾倒”。它不做复杂的计算，默认也不进高强度的压缩。它的设计哲学就是“快”，因此它在写入速度上拔得头筹是符合预期的。

* **Parquet为什么比Feather慢？**
  * Parquet在写入时，做了很多“额外但有益”的工作：
      1. **数据重排：** 它需要将Pandas在内存中偏向于行式组织的DataFrame，转换成列式结构。
      2. **执行压缩：** 对每一列数据应用压缩算法（默认是`snappy`，速度很快）需要消耗CPU资源。
      3. **计算元数据：** 它会计算每个数据块的一些统计信息（如最大/最小值），并把这些信息和整个文件结构图（Schema）写入文件末尾。
  * 所以，Parquet用更多的写入时间，换取了更小的文件体积和更智能的读取能力。你观察到的“两倍耗时”就是这权衡（Trade-off）的体现。

* **CSV为什么惨不忍睹？**
  * 你的“30倍”这个数量级非常说明问题。根本原因在于**数据类型的转换**。CPU处理二进制的浮点（`float64`）和整数（`int64`）非常快，但要把这些数字转换成人类可读的十进制文本字符串（比如 `1081234567`），再逐个字符写入文件，是一个极其缓慢的过程。CSV的写入慢，就慢在这里。

#### **2. 关于全量读取性能：`Parquet ≈ Feather >> CSV`**

* **为什么Parquet这次能追上甚至反超Feather？**
  * 这是一个非常有趣的观察点！按理说，Feather是直内存映射，应该最快。但Parquet在这里有两个隐藏势：
      1. **I/O优势：** 由于Parquet文件被压缩过体积更小。这意味着从硬盘读取到内存的数据总量少。在硬盘速度是瓶颈时，读取一个500MBParquet文件显然比读取一个1GB的Feather文件快。
      2. **高效解压：** 现代CPU的解压速度快得人。像`snappy`或`zstd`这样的算法，其解压速甚至可能超过硬盘的读取速度。
  * 因此，最终的读取时间是 `(从硬盘读数据的时间) +(解压数据的时间)`。对于Parquet，可能是 `(较短的取时间) + (极短的解压时间)`，其总和就可能小于或于Feather的`(较长的读取时间) + (几乎为零的解压间)`。这完美展现了现代数据工程的权衡。

#### **3. 关于列读取性能：`Parquet ≈ Feather >>>>> CSV` (80倍的差距！)**

* **这正是列式存储的“杀手级应用”！**
  * 你用实验数据雄辩地证明了我们之前的理论。当 `pd.read_parquet(..., columns=['close', 'volume']` 执行时，它会读取Parquet文件的元数据，找`close`和`volume`这两列数据在文件中的具体位置，后**只**把这两块数据从硬盘加载到内存。其他所有（`open`, `high`, `low`）的数据被完全跳过，连盘的磁头都不需要去碰它们一下。
  * Feather也是同理，因为它基于Arrow的列式内存局。
  * 而CSV呢？为了读取这两列，它别无选择，只能把**个文件的每一个字节**从头读到尾，在内存里把每一行逗号分割，然后挑出你想要的那几列，再丢掉其他的。的80倍耗时差距，就是这无效I/O和无效计算的代价。

---

### **总结与策略制定**

通过这个实验，我们得到了一个非常清晰、由数据支撑的决策依据：

* **对于我们项目的“数据基石”——即一次写入、多次读取分析的历史数据，Parquet是毫无疑问的王者。** 它用一次性的、可接受的写入开销，换来了巨大的存储空间节省和后续几百上千次分析中极高的读取效率。
* **CSV只应作为系统间交换数据的“通用语”，一个临时的“信使”，一旦数据抵达我们的分析环境，就应立即将其转换为Parquet格式进行归档。**

### **下一步：深入Pandas数据操作**

我们现在已经掌握了如何高效地**存储**和**读取**数据。下一步，我们将聚焦于如何更深入地**操作**和**分析**这些已经加载到DataFrame中的数据。这会是我们日常进行策略研究时最高频使用的技能。

根据我们之前的学习计划，接下来的内容将包括：

1. **数据的精确选择与切片：** `loc` 和 `iloc` 的高级用法，以及布尔索引（Boolean Indexing）。
2. **分组与聚合 (Group By)：** 这是数据分析的核心，例如，如何计算每个月的平均交易量，或者每个星期三的平均波动率。
3. **合并与连接 (Merge & Join)：** 如何将不同来源的数据（比如K线数据和新闻情绪数据）整合到一起。
4. **数据清洗：** 处理缺失值和异常值。
